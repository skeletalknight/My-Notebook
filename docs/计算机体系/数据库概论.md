# 数据库概论

数据库将数据与应用隔离，有利于处理海量的数据

## 数据库管理系统

- 数据定义语言
- 数据操作语言
- 受控访问
	- 安全：鉴权与限制
	- 完整：数据一致性
	- 并发控制：共享访问
	- 恢复控制：应对软件、硬件故障

## 数据库类型

- 关系数据库：使用关系模型构建的数据库，最通用、可靠、完善的数据库选项，如**MySQL**、**SQLite**
- 文档数据库：以 JSON 格式存储数据，支持灵活的数据结构和查询，如**MongoDB**
- 键值数据库：通过键值对存储数据，提供高性能的读取和写入操作，适用于缓存和会话存储，如**Redis**
- 列族数据库：以列族的方式存储数据，适合处理大规模数据并支持高可用性和可扩展性，如**Cassandra**
- 图数据库：以图结构存储数据，专注于节点、边和属性，非常适合复杂的关系建模和查询，如**Neo4j**



## 分布式数据库

### 大数据的4V

- **Volume**：数据一直都在以每年50%的速度增长，到2020年，世界将拥有35ZB的数据
- **Variety**：大数据将存在越来越多的非结构化数据
- **Velocity**：数据有效的时间窗口很小，系统需要在秒级给出结果（产生和处理速度快）
- **Veracity**：数据具有很大的不确定性，因而价值密度很低，需要从大量数据中提取高价值数据

基于以上性质，大数据将很依赖于分布式储存和分布式处理技术

### CAP理论

为了分析分布式数据的性质，我们采用CAP理论

- **C（Consistency）：**保持数据一致性，在分布式环境中，要求所有节点在同一时间具有相同的数据

- **A（Availability）：**可用性，是指快速获取数据，可以在确定的时间内返回操作结果

- **P（Tolerance of Network Partition）：**分区容忍性，是指当出现网络分区的情况时（即系统中的一部分节点无法和其他节点进行通信），分离的系统也能够正常运行，也就是说，系统中任意信息的丢失或失败不会影响系统的继续运作。

CAP理论认为，一个分布式系统不可能同时满足以上所有的需求，但可以根据需求进行侧重，如：

- **CA：**保证了一致性和可用性，但这种做法会严重影响系统的可扩展性

- **CP：**如果由于网络分区而无法保证特定信息是最新的，则系统将返回错误或超时
- **AP：**当由于网络分区而无法保证数据是最新的时候，允许系统返回不一致的数据

对于一个分布式系统而言，P是前提，必须保证

### 大数据技术

#### Hadoop

Apache软件基金会旗下基于Java开发的开源**分布式计算平台**

核心是分布式文件系统**HDFS**（Hadoop Distributed File System）和分布式处理框架**MapReduce**，其原理如下：

- **HDFS**：

	- 采用**Master/Slave**模式：

		- Master主要承担客户请求处理、数据分配汇总以及节点协调任务
		- Slave主要负责接受数据、数据存储和计算的过程，并把结果返回给调用者
		- 一个Hadoop集群包含单独的Master节点（**NameNode**）和多个Slave节点（**DataNode**）服务器（逻辑意义上）
		- **NameNode**会保存文件系统的具体信息，包括文件信息、文件被分割成具体块的信息、以及每一个block块归属的**DataNode**的信息，而**DataNode**则会管理并上传数据块的信息。这保证了单一的接口。

	- 存储上，将文件切分成固定大小的数据块（默认为64MB），每块具有三个副本，按照本地两份，异地一份原则储存

	- 通过分布式存储，加上冗余存储，以兼顾可用性和效率

- **MapReduce**：

	- **Mapper**负责“分”，即将复杂问题分为若干个简单、可并行、读写效率高的问题
	- **Reducer**负责对map阶段的结果进行汇总

### 