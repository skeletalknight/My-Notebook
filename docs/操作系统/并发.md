# 并发

## 打破串行思维

C 语言状态机的多线程：共享的全局变量，独立的帧栈列表

汇编语言状态机的多线程：共享的地址空间，独立的寄存器（栈指针SP，指向不同的内存位置）

### 状态迁移的原子性假设失效

多线程下，状态迁移再也不是顺序执行：

**共享内存**推翻了 “原子性” 假设——load 读到的值都可能是别的线程写入的

!!! note "并发1+1"

    在两个线程下分别执行1000次sum++，其结果是不确定的——实际上它可以在2-2000直接随机浮动
    对于最小的情况，解释如下：
    - A线程读取后，B线程写入999次，A再写回		|           sum=1
    - 而后B再读入，A写入999次，B再写回		   |	  sum=2

### 程序顺序执行的假设失效

编译器进行程序优化时，必须基于顺序执行的假设——然而，在并发的情况下，这种优化可能是灾难性的。

即使使用`while (!flag); `这样的直接标志，也有可能因编译优化而带来意想不到的结果。

我们可以使用特殊标记，如`volatile` 修饰变量，来避免优化——但这会带来运行效率的大幅下降

### 全局指令执行顺序的假设失效

我们认为的共享内存，在所有线程视角眼中的等价的——然而实际上，处理器内部还隐藏了一个动态编译器和缓存共同作用：

具体而言，由于CPU的多级缓存，一项写入可能一直在CPU的缓存上，而不会及时写入主存，从而不会被其他线程共享。同时编译器可能会进行乱序执行指令来优化指令，造成意外的逻辑错误：

```c
// 线程 A
x = 1;
ready = true;  // CPU 可能先执行 ready = true，再执行 x = 1
// 线程 B
while (!ready) {}
printf("%d", x);  // 可能打印未初始化的 x（如 0）
```

这使得使并发程序的行为变得更难理解：并发程序执行的结果，甚至可以不是<u>所有执行过指令的某个排列顺序运行的结果</u>！

<img src="post_content/并发/image-20250418141522045.png" alt="image-20250418141522045" style="zoom: 80%;" />

!!! note "x86和arm的内存模型"

    x86 架构的内存比 ARM 更接近 “真正的共享内存”
    x86架构采用**强一致性内存模型**：
    - 写操作（Store）的顺序对所有 CPU 核心可见的顺序一致。x86 的每个 CPU 核心有一个写缓冲区，保证了写操作的全局顺序一致性
    ARM 采用**弱一致性内存模型**:
    - CPU 和编译器可以自由重排序内存访问。若要保持顺序写入，要求程序员手动插入内存屏障。
    
    但无论是x86还是ARM，都使用了 MOESI缓存一致性协议，确保了当一个核心修改数据时，其他核心的缓存会**自动失效**，强制从主存或最新缓存读取。

## 互斥

为了阻止前文所说的问题，我们可以在可能发生冲突的地方，人为设置锁机制，保证临界区仍满足执行的原子性。通过放弃部分并行，来实现计算的可靠性。

### Peterson算法

Peterson算法是经典的，应用于**双线程**的互斥算法。它的核心理念是举旗+谦让。

首先，当需要访问临界区时，线程会举旗说明，同时将`turn`优先交给对方。这样可以保证，同时访问时，先来的线程使用，并避免同时访问。

```c
Pi:
flag[i] = ture; turn = j;
while (flag[j] && turn == j);
critical section;// 访问临界区
flag[i] = false;
 
Pj:
flag[j] = true; turn = i;
while (flag[i] && turn == i);
critical sectionl// 访问临界区
flag[j] = false;
```

Peterson算法提供了一种独立于硬件的互斥锁的实现形式，然而它对更多线程的拓展性并不好。

### 自旋锁

通过在硬件上引入原子操作，我们简洁地可以实现多线程的互斥锁。

硬件层面的原子操作**要么完全执行，要么完全不执行**，不会被其他操作中断或干扰，通过以下方式实现：

- 总线锁定

	执行操作时，CPU 会通过锁总线（Bus Locking）或缓存一致性协议（如 MESI）确保：

	- 该指令独占访问目标内存地址。
	- 其他 CPU 核心在此期间无法读写同一内存地址。

- **单指令完成**：操作在一条指令内完成，**不会被中断**。

常见的，用于实现互斥的原子操作如Test-and-Set (TAS)、 Compare-and-Swap (CAS)、 Load-Linked/Store-Conditional (LL/SC)等

以TAS举例，通过`xchg`保证原子交换，可以实现临界区的加锁和独有

```assembly
; 使用TAS指令实现自旋锁
spin_lock:
    mov eax, 1          ; 锁定值
    xchg eax, [lock_var] ; 原子交换
    test eax, eax       ; 检查旧值
    jnz spin_lock       ; 非零则继续自旋
    ret

spin_unlock:
    mov dword [lock_var], 0 ; 释放锁
    ret
```

当交换失败，即未获得锁时，线程会不断检查，直至获取锁。这种占用CPU，等待锁释放的方式被称为自旋锁。

### 互斥锁

互斥锁在自旋锁的基础上，允许等待锁的线程暂时休眠，减少CPU占用。这种中断依赖于操作系统的介入。

在未能获取锁时，类似于进程中断，操作系统会存储线程的信息，并记录到等待队列当中。当锁被释放时，会自动从等待队列中选取线程获取锁继续执行。

互斥锁保证了在等待锁时，线程不会持续占用CPU资源，然而休眠和唤醒会引入额外的时间开销（微妙级），因此更适合长时间的临界区处理。

同时，唤醒的也有着不同的策略。一般会结合先进先出（FIFO）和优先级（非公平锁）。

为了让操作系统能明确等待队列，互斥锁的变量需要由操作系统来定义（自旋锁则没有该限制）

### 读写锁

RWLock（读写锁）是一种特殊的同步机制，它在互斥锁的基础上进行了优化，区分了读操作和写操作，以提高并发性能。其核心思想是：**读操作可以共享，写操作必须互斥**。这种设计适用于读多写少的场景，能够显著减少线程间的竞争。

在读数据上，多个线程可以同时持有读锁，访问共享资源（并发读）。只要没有写锁被持有，读锁的获取总是成功的。

而在写数据上，类似于互斥锁，写锁是独占的，同一时间只能有一个线程持有写锁（与任何读锁或其他写锁互斥），所有读锁和其他写锁的请求会被阻塞。

读写锁也可以设置读优先、写优先的不同策略，适应不同的业务需求。

### **RCU（Read-Copy-Update）**

RCU（Read-Copy-Update）类似于读写锁，但是它有延迟修改的特性。RCU的核心思想是**“读无锁，写延迟回收”**。RCU能够最大化读性能，在Linux内核当中被广泛使用。

在读数据上，RCU完全不设任何锁限制，性能极高

而在写数据上，RCU会先创建数据的副本（新版本），修改副本。然后通过**原子替换指针**，保证新数据对后续读数据可见。而原本的旧数据则会在所用读线程退出后，**延迟回收**

RCU写操作的开销较高，但换取了读操作的近乎无开销，适合读极多、写极少的场景。	

