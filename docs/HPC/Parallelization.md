# Parallelization

对于一个单处理器系统，在任何时刻它都只能处理一个进程的代码。

进程独享存储空间和资源，CPU通过时间片的切换实现并行假象。

为了实现真正的并行计算，可以使用线程运行在不同执行单元——线程共享进程的资源

当不同执行单元通过共享存储空间的方式通信（如OpenMP），即本地并发计算

当执行单元分布在不同计算机时，则可以通过消息传输库MPI实现进程间的通信

并行计算需要注意的步骤：

- 划分
- 通信
- 整合
- 映射

| 特性         | MP                             | MPI                              |
| :----------- | :----------------------------- | :------------------------------- |
| 全称         | Multiprocessing                | Message Passing Interface        |
| 内存模型     | 共享内存（Shared Memory）      | 分布式内存（Distributed Memory） |
| 核心概念     | 多处理器/多核心并行执行任务    | 进程间消息传递                   |
| 主要应用场景 | 多核处理器、服务器、超级计算机 | 计算机集群、大规模并行计算       |
| 常见实现     | SMP、AMP                       | MPICH、OpenMPI                   |
